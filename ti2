
So let's resume with the second section then, which should put us on page 18 of your notes. All right. So this section is entitled Feedback Control. I've been talking to you for an hour and a half and we haven't done any control yet, even though we're on a control theory seminar. So you probably want your money back by now, right? So let's put that right.

This section's entitled feedback control, and we're going to approach the topic from the perspective of the frequency domain uniquely. I'm going to use the Nyquist plot as the main working tool to do this. But before I can get to that, I need to do a few prerequisites. I need to explain the ideas of complex plane mapping. And once we've got the Nyquist plot under our belt, we'll use it to do some design.

We're going to design a phase lead compensator. And I rather expect that lunch is going to come just after the phase compensation part of this section, so after lunch we'll come back, not too worried that we haven't finished this, because I know how the timings work. And then we'll do sensitivity and tracking and robustness at the end. We should be about right for time if we hold to this.

Now in 1927 there was a young engineer at a place called Bell Labs in New York. He was on his way to work one day and he was crossing the river Hudson by ferry. His journey to work took him by that means. He was thinking about a problem that he had at work. It was to do with the distortion that appeared whenever you applied high gain to telecommunication amplifiers. It was in 1927, and the wisdom of the day was to put very large gain into telecommunication amplifiers, in a bid to get, well, high signal strength, I suppose.

What he realized was that if he fed back all the output of his high gain amplifier in such a way as to throw away all the gain that he'd worked so hard to achieve, he could win linearity and bandwidth. You got low gain, but you got linearity and bandwidth. And this was the first time that anybody'd ever realized that. His name was Harold Black. Of course, he's known today as the inventor of the operational amplifier, but in 1927 nobody knew who he was.

And he wrote this idea down on a copy of the New York Times, and when he got to work he had that signed and turned into a proper patent application. And then his problems began, because nobody believed him. He said at the time it was like trying to patent the perpetual motion machine. It took nine years to get that particular patent through. Nowadays of course, we recognize it for what it is, which is a brilliant idea, and one which led, ultimately, to the ideas behind the operational amplifier. Harold Black.

I thought you'd be interested to see Harold Black. This is what he looked like in 1927. Graduated from Worcester Polytechnic Institute, and went directly to work at Bell Labs which was the research arm of AT&T. The idea behind Bell Labs was to maintain the monopoly on the telephone company that AT&T had. And it was a unique situation, where you had a commercial organization pumping money and expertise into research and development.

And Harold Black thrived. He's best known for his invention of the operational amplifier. This is what he looked like at the time of his retirement, but to he retired with about 260 something patents to his name. He was a very, very productive member of staff, and a very nice man too, which is why he gets his own slide in my seminar. That's Harold Black. The big names like Black, you read about them in your electronics textbooks. And it's a dry as dust name, but it's nice to see the guy, isn't it? I think so anyway.

All right, this is feedback control. And the type of system that I'm going to talk about has this kind of a structure. Sometimes it's called a canonical structure. That name just means the simplest kind of structure that you can think of. Canonical comes up quite a lot. So it's a system whose objective is to make an output follow an input. We saw that in the very first slide today. And there are three components inside this loop.

Now this one is called-- this is the plant, right? Now that name is a generic name which has arisen for the object whose output we are trying to control. It may be a motor, it may be a power supply, it may be a ship, could be anything you like. Its generic name is a plant. And the name is arisen because of the use of control in manufacturing. So it's that kind of manufacturing plant, it's not something that's green with leaves sticking out of it. It's that kind of a plant.

Now in order to apply feedback we need to measure the output. And that measurement itself may introduce some additional dynamics into the loop, so they're accounted for by this block here, called-- well, I've marked it sensor. And the measured output then is compared with the input, and the error between the two is manipulated by a controller, something that we design. I'm going to assume this is the only component we can influence in the design.

The controller's job is to take the error in the loop, the difference between the input and the measured output, and manipulate it to produce a control effort, which is the input that's actually applied to the plant. This is called closed loop control using negative feedback, because a negative sign appears here at the summing point.

Now when you properly apply feedback a lot of very desirable things happen, as Harold Black found. You can reduce or eliminate steady state error. You can reduce the sensitivity of the system to parameter changes like the temperature induced changes on capacitance, or something like that. You can change the gain or the phase. You can make unstable systems stable, but note, when properly applied. I think most of us have done the opposite of most of these things if we don't properly apply this.

You can make a stable system unstable with the application of feedback, which is one of the drawbacks of feedback. Got to get the design right. And you can also influence it less with load disturbance and nonlinearity. So lots of benefits.

The notation I'm going to use is captured on this slide. The input I'm going to denote with the letter r, r for reference, let's say. And the output y. And the three transfer functions of the components in the block, they'll be uppercase letters F, G, and H for controller, plant, and sensor respectively. Remember each of these is a transfer function, potentially.

And then the signals appearing around the loop, I'm going to call the measured output y sub m, m for measured. The error, well predictably it'll be e, and the control effort is u. So perhaps now you can see when we talked about differential equations and transfer functions in the first chapter, we used G as the transfer function, u is the input, and y is the output. That's this part of the system that we were talking about. These other terms appear once we apply feedback.

Now to analyze this loop, the best way to proceed is to focus your effort on the error that appears in the loop. And of course the arrow is the difference between the input reference and the measured output, or by the linearity property of the transfer function, that's just simply h times y. And the output is represented in terms of error by F times G. So y equals F times G times e.

Now if you take the first of these equations and substitute it in there, what you find is this, y equals F times G times r minus H times y. Y appears in two places here, so let's isolate it on the left. Y times 1 plus FGH equals FGr, and now I have everything I need to construct the transfer function of the entire system from r to y, the output divided by the input. It's going to be F times G, and we divide by this term, 1 plus FGH. That is the closed loop transfer function. Very important transfer function, because after all, this is what we're trying to do, make y follow r. One of the objectives of control. It's the objective of control.

Now this transfer function contains within it the term FGH. That transfer function is very important. And it is known as the open loop transfer function. To determine what it is, you take a pair of scissors or something and you cut through the loop at the input to this summing junction here. And all you do is you go around the loop, multiplying by each transfer function in sequence as you come to it. F times G times H. The open loop transfer function. It turns out that this is the transfer function that defines truly what the properties of the loop are. It's so important, it's usually given its own symbol, L. L Is the open loop transfer function.

Now of course these three components F, G, and H, are all transfer functions. And therefore they have their own set of poles and zeroes. Let's take a look at how those poles and zeroes influence the poles and zeroes of the closed loop. We represent the plant by the polynomials beta 1 and alpha 1. So remember, beta 1, the polynomial is from the input side, terms involving u, they define the zeroes of the plant. Alpha 1, the polynomial involving coefficients on the output side, they define the poles of the plant. Likewise, beta 2 and alpha 2 are the poles and zeroes, sorry, the zeros and poles, respectively, of the sensor.

I'm going to assume, just to keep things simple, that the control is just a simple amplifier. It's got a gain, but no other effect. And that gain is k, k is some arbitrary gain. So we'll drop these three terms directly into this transfer function here, and what we find is that the closed loop transfer function is k times beta 1 over alpha 1-- that's F times G-- divided by 1 plus FGH.

Now let's simplify it a little bit by multiplying through by alpha 1, alpha 2. So we've got a nice simple ratio now of polynomials. And we find that the closed loop transfer function is k times beta 1 times alpha 2 over the denominator, is alpha 1, alpha 2, plus k times beta 1, beta 2.

So where are the closed loop poles and zeroes? Well, the closed loop zeroes are pretty easy to find. They come from the zeroes of the plant, and the poles of the sensor. Anything which is a zero in the forward path, that is also a closed loop zero. Anything which is a poll in the feedback path, that is a closed loop zero as well. Pretty easy to find out where the zeroes are, as long as you know these transfer functions. Now, the zeros of course contribute to the residues of the time response, but they don't influence the stability of the response. It's the polls that tell us the stability, together with a lot of other information.

So where are the polls? Not so easy to find, because they are the sum of two different polynomials. And to find each of these polynomials we've got to expand these polynomial products. And then we have to combine like terms and refactorize them. So the closed loop poles are not easy to find, they're not obvious, anyway. But they're important.

Now you could take two different views of this problem. Here is the transfer function of the closed loop, FG over 1 plus FGH, or 1 plus L. And finding the closed loop poles is equivalent to saying what zeros have I got in the denominator of this? Do any of them lie in the right half plane? Because anything that's a 0 of 1 plus L is going to be a pole of the closed loop transfer function.

In this chapter we're going to take a frequency dependent view of this problem. And I'm going to show you how to find the answer to this question in terms of frequency response of L. That is the basis on which we're going to approach the problem. Another way of saying this is, well, we write the closed loop transfer function in this way, and then the poles have easily-- a little bit easy, because they're this polynomial in the bottom here. Well, we've got to work it out, but this polynomial has roots. And we would like to know whether any of these roots lie in the right half plane.

I'm going to address this problem in the third chapter, because it turns out that there's a very nice technique called the root locus plot which allows us to answer this question in terms of varying k. What we do is we plot the polls, vary k, and look what happens to them in the complex plane. That result is a root locus plot. For now though, we're going to look at the zeroes of 1 plus L of s and determine whether any of them are in the right half plane. The technique, of course, I'm sure you know, is called the Nyquist plot.

Now in order to explain it, I need to introduce two concepts. And these concepts have to do with the mapping of points and contours in the complex plane. And the two concepts of importance are called encirclement an enclosure. So I have here two-- well, two complex planes. Each of these planes has a contour which I've marked gamma, and two points marked a and b. Now the only difference between these two is that the direction about which we are moving around this contour is different. Here it is a counterclockwise direction, and over here it's a clockwise direction. Otherwise these two graphs are the same.

So first of all, encirclement. Now encirclement, conceptually, is pretty easy. A point is encircled if it's inside the contour. A is inside the contour, therefore it's encircled. B is not inside the contour, it's not encircled. Same thing over here. A is encircled, B is not. Enclosure is a bit different, because enclosure takes into account the direction about which we traverse this contour.

And the law is this. If we go around this contour in the counterclockwise direction, as we move around it, all the points on our left are enclosed all the points on our right are not enclosed. So this yellow shaded area represents an enclosed area. And in this context, a would be enclosed as well as encircled, and b would be neither enclosed or encircled. If we change the direction of traversal of the contour, well, the encirclement doesn't change but the enclosure does. Because now as we move around this all the points on our left are enclosed, including b. All the points on our right are not enclosed, including a. OK?

Now these are nice simple contours. They're called non self-intersecting contours. But when we look at the way that contours appear in the complex plane, they can do all sorts of weird, loopy shapes. Here are a couple of what are called self-intersecting contours. Two points again marked a and b, and I'm going to look at the ideas of encirclement with respect to these. First of all, you see, points can be encircled more than once. You can have multiple encirclements. Enclosure is a binary thing, you're either enclosed or you're not. But encirclement, you can go around something more than once.

Here obviously, b is being encircled twice. You're sort of lassoing it two times by this contour, but you're only encircling a once. Neither of which is enclosed, because they don't lie permanently on the left of the contour. And over here, well, you've got the same number of enclosed-- of encirclements, but they're both enclosed, because now they lie on the left of these two contours. OK? So you can encircle something once or twice or as many times as you like.

Now for some functions, you see, it's really easy, isn't it? If you've got a function like this, y equals some function of x, where x and y are both nice, easy, real numbers, you know that you can plot this on a graph where you have axes of x and y. This would be called a real function of a real variable. Y is real and x is real, and the world is a nice place.

Sometimes however, x and y, or one or the other, might be complex. And where both of them are complex, you can't plot them on a simple graph like this, you need two different complex planes. And the relationship between them is called mapping. That represents the function that maps x on to y. Now so think of a mapping as a function, a function of a complex variable. Each point over here is going to be mapped to at least one point over here.

Now certain functions can map single points over here to multiple points over there. That can happen. Certain others map one point to one point. They are called one-to-one mappings. And it turns out that all transfer functions are one-to-one. They map a single point in one complex plane to a single point in another complex plane. They are one-to-one mappings.

Now for values-- for functions which are like that, contours turn out to be contoured after they map. That's pretty obvious, because imagine that you have a series of points around a contour in one plane, and you're mapping that contour with a single valued function. Every point along that contour is going to turn into another point along a different contour in the plane that's being mapped onto. As you go around these points, you can see you keep mapping each one to one and only one point over there. Eventually you get back to where you started from. So a closed contour here is a closed contour here, for a one-to-one function, or a one-to-one mapping.

However, the shape of this contour, as well as the direction that it goes round, might well be different from this one. Those are the properties of the function that we use to do the mapping. Almost there. Now those properties were captured in 1855 in something called the Principle of the Argument, which was put forward by a French mathematician called Augustin-Louis Cauchy.

You may have heard of Cauchy. He doesn't have his own biographical slide because he certainly wasn't a very nice man as far as I've been able ascertain. He was around at the time of the French Revolution, and all sorts of nasty things happened. But anyway, he was a rather brilliant mathematician. And he established something called the Principle of the Argument, which connects these properties of direction and whether or not this fellow encircles the origin. Those two things, direction change, and encirclement of the origin, they're connected with the number of poles enclosed over here.

Right. Encircled, I'm sorry. Number of poles and zeroes encircled. So assume that the gamma s contour-- that's this one-- assume that that encircles z zeros and p poles of the function that's used for the mapping. So we know how many poles and zeroes of delta of s, in this case, are contained within this contour. And you calculate the number N, that's the difference between the number of zeros and the number of poles encircled by gamma s.

The principal argument says that the contour that's mapped encircles the origin that number of times. But it also tells us about the direction. Because if n is greater than zero, the direction doesn't change. If n is less than zero, the direction does change. And if n is zero, meaning there's the same number of zeros and poles encircled by gamma s, it doesn't encircle the origin in the first place.

So we can say something about-- whoops, excuse me-- about this contour based on knowledge of the poles and zeroes encircled by this one. So let's say something about it. How many poles and zeroes are in here?

[INAUDIBLE].

Not exactly. We don't know. We have absolutely no idea. We only know a little bit about the difference between the two numbers. So let's look at it. Firs of all, are we encircling the origin? Yes, we are, right? We've encircled the origin. So clearly we're in case one or case three. Well, which one are we in? It depends on the direction. So what happens? This direction goes around in a sort of clockwise direction, and this one-- well, the direction's changed. It's counterclockwise. So we're obviously in case number three, because gamma delta encircles the origin in the opposite direction, and it encircles it n times.

What does n mean? Well, it means we've got more poles than zeroes. So we have absolutely no idea how many of either are in here, but we know we've got one more poll than we've got zero. That's the only thing that we know from the Principle of the Argument. But it was enough for Harry Nyquist to come up with a rather brilliant theorem which will answer our problem. You're going to see that in a second.

Now, before I tell you about it, I want to tell you how you work out easily how many times you encircle the origin. What you do is this. Any of these graphs. Let's take this one. You start at the origin, and you draw a straight line. And you draw that line in any direction you like, it doesn't matter. The only thing that's important about it is it goes far enough that it cuts all the contours.

So here for-- and what you do then is each time you cut a contour in the counterclockwise direction, you count plus 1. So for counterclockwise, associate that with positive, and for clockwise, associate it with negative. So here you're going clockwise, that's minus 1, clockwise again, that's minus 2. So this contour encircles the origin minus 2 times.

This one, well, you draw the line anywhere you like. Here you're going clockwise, minus 1, counterclockwise, plus 1. This doesn't encircle the origin. But you could have told that by just choosing this line, and it wouldn't have cut any contours in the first place. This one, well you've got a clockwise, plus 1, counterclockwise minus 1, that does not encircle the origin. And here you've got clockwise, clockwise, clockwise, you've got 3 negative encirclements of the origin. Really easy to tell. OK? That's all the information we need about complex plane mapping for now.

Now the innovation that Nyquist had was he applied the Principle of the Argument to obtain information about stability. And he chose a path which enclosed the entire region of instability in the complex plane. The entire right half plane is bounded by what's called the Nyquist path. And it's typically drawn as this shape, it's a big D. But you're supposed to imagine that the radius of the circley part, the bendy bit, is infinite, so it covers the entire right half plane.

Now there's something I forgot to tell you. And it's this. This thing, all this stuff about the Principal of the Argument, it holds perfectly well, providing that none of these points on here happens to be a pole. Because if one of these points was a pole, what's this going to look like over here once you map it? The pole of the transfer function is infinite. Right. So if you've got a pole lying on this contour, you can't apply it, because it doesn't turn out to be a closed contour over here. You've got to make sure you haven't got any poles on the contour.

Well, that's a problem for Nyquist, because the Nyquist Path-- he's trying to determine stability-- might go through poles which are legitimately on the imaginary axis. They might comprise systems that we would think of as stable, or at least giving us a bounded response. So to get around this problem, he chose a contour which deliberately avoided any poles. And he just sort of knocked little dents in the side, he went like that, just knocking an infinitely small dent in the side of this contour, to just get around that.

And if you wanted to, you could make another little segment out of that and apply the same rule that I'm going to tell you in a minute. The point is, he's enclosed the region of unstable polls by the Nyquist Path. And then what we're going to do is we're going to map this using the open loop transfer function L of s. Here's the Nyquist Path. Now note the direction that we're going around this. This is counterclockwise. I'm staying with a counterclockwise convention here.

And what you find when you use this technique is that points infinitely far up the imaginary axis correspond to infinite frequency. And point at the origin corresponds to zero frequency. So the positive imaginary axis corresponds to a line of varying frequency, from 0 at the origin to infinity at infinity up there. And you can expect that some transfer function is going to have a magnitude which varies from, say, some finite value towards zero.

So this point here typically gets mapped towards the origin of the curve that's over here in the mapped contour. This is typically how you would construct a Nyquist curve. Now he then applied the Principle of the Argument. And he said, OK, what's the difference between the number of poles and zeroes in here, and the number of times that I've encircled the origin? That'll tell you quite a lot about L of s. But we're not interested in L of s. We want to know something about 1 plus L of s. That's the denominator of the closed loop transfer function.

So what he did was very clever. Instead of examining encirclement and enclosure of the origin, he examined encirclement and enclosure of the point minus 1. And he realized that this would tell him the information he needed about the transfer function of 1 plus L of s. It led to the Nyquist Stability Criterion. In its full form what it says is that we need no right half plane zeros of this. Right? No right half plane zeros of 1 plus L of s.

Remember, the number N is the difference between the number of zeros and the number of poles that are encircled by the contour we're mapping. Well if there's no zeros in there, then n must be equal to minus P, the number of poles that are in there. You have to know, to apply Nyquist, how many poles are in the right half plane before you apply it. So you've got a pole over here. What could we say about the open loop?

Anything that has a pole in the right half plane is unstable, isn't it? So for unstable open loop systems, we can apply Nyquist's criteria by counting the number of encirclements of the minus 1 point, and stipulating that they must be made in the opposite direction to the Nyquist Path. That's for systems that are open loop unstable. For systems that are open loop stable, and there's a lot of those-- in engineering there's a lot of open loop stable systems-- there are no poles in the right half plane.

And since there are no right half plane zeros either, you need no enclosures of the critical point. That is the simplified Nyquist stability criterion. The critical point must not be enclosed. So let me show you an example of a stable and an unstable system. Now on the left I have an unstable-- sorry, a stable system, open loop stable system, and closed loop stable system. And the Nyquist curve, this is the curve for positive frequencies, does not enclose this. We're going around it in a counterclockwise direction. Remember, all the points on our left are enclosed, the critical point is not among them. So this is a closed loop stable system.

Here is a closed loop unstable system, because the Nyquist curve encloses it. The critical point now lies inside the shaded area. It's on our left as we go around the contour, and therefore it's enclosed. Now the direction of increasing frequency is actually like this. And this is the direction that you'll find in most textbooks when they show this kind of graph. Because when we typically measure a frequency in the lab, it's instinctive, I think, to start at zero Hertz and wind the dial on the signal generator upwards, to infinity. And want you're doing there is you're passing along this sort of direction, that's increasing frequency.

The reason I chose not to do it that way is that, if I'd done that, I'd be going the opposite direction around here. I'd be violating the convention of counterclockwise angles being positive. So you've got to be careful about doing that. So I prefer this convention, which is the mathematically correct convention. But just remember for now that increasing frequency passes that way. OK?

Now yeah, I think-- did I put him in there? Yeah, I did. There he is. Harry Nyquist was another nice guy. He was a colleague of Harold Black at Bell Labs. He was a very productive member of staff at Bell Labs. He was born not in the United States, but in a place called Nilsby, in Sweden. And his family emigrated to Dakota in 1907. He was a rather brilliant student, he wanted to be a teacher. He went and achieved bachelors and MSc degrees in two consecutive years, and then two years later got a PhD. Try doing that today. He was a rather brilliant student.

And he continued at Bell Labs, making significant contributions until 1954, when he retired to set up a consultancy in a place called Pharr in Texas, where he died in 1963 I think it was. Now he's known for three things. The first of which is the Nyquist plot. The second-- this seems to be the three things that most people know him for. The second was work he conducted with a man called Johnson on thermal noise in resistors. It's still called Johnson-Nyquist noise. I wonder if anybody knows the third thing that Harry Nyquist is really famous for.

Nyquist frequency. That's correct. It's the maximum unique frequency in any sample system. It's still called the Nyquist frequency today. So he's known for three things. And he retired with-- I think it was 138 patents to his name. Very productive and clever man. Now the thing is that in addition-- oh, here you go. This is his paper. Well, it's taken a reprint from the Bell Labs technical journal in 1932.

And the reason I think it's interesting is that in the original transcript, the critical point was on the opposite side to the one that we know it today. It's just the way that the theory worked out. It's over here at plus 1. And it was corrected by Heinrich Bode, who gave his name to the Bode plot, who was also at Bell Labs. A lot of these famous people were at Bell Labs contributing theory which was fundamental to control, before control theory was a separate subject on its own right. All this stuff came from telecommunications theory into the world of controls. It's quite interesting how all of this sort of came together.

Now in addition to measuring stability in a sort of binary yes or no sense, almost unfortunately, the Nyquist plot is used to measure performance as well. And I'll explain what I mean by unfortunately in a little bit. This is a part of the Nyquist curve in the vicinity of the critical point, and you can guess that because the critical point is not enclosed in this case, this will be a closed loop stable system.

And we use the proximity of the curve to the critical point as a measure of what is called relative stability. And there are two ways in which we do this. The first way is that we examine the point at which the open loop gain magnitude falls below one. That is called the gain crossover frequency. Now because this is a polar plot of the open loop transfer function, a vector from the origin out to any point on this curve corresponds to the magnitude of the open loop plot, that's the length of that vector.

So when this vector in red here has length 1, that's the gain crossover frequency. And if we measure the angle between the negative real axis and that vector, that is called a phase margin. Notice that the phase margin in this case is a counterclockwise angle, therefore it's positive. Stable systems have positive phase margins.

That corresponds to the amount of clockwise rotation that we could apply, the amount of extra phase lag in this case, before the Nyquist curve encloses the critical point and we have a closed loop unstable system. That is phase margin. We almost always have a phase margin in systems. Almost always.

The other frequency at which we measure stability is the frequency at which we have 180 degrees of phase shift. Plus or minus 180 degrees, plus minus pi radians, whatever you like to think. And that frequency, our gain should be below 1, because it's not. We've obviously enclosed the critical point. The difference between the magnitude at that frequency, which is called the phase crossover frequency, and 1, that is the gain margin.

Now the gain margin is normally written and expressed in decibels, which is why it's easy to extract from a Bode plot. If you extract it from a Nyquist plot, you've got a slightly different calculation to do, and you've got to take that in dBs. That is the gain margin. It's the amount of extra gain we could apply at this frequency, assuming phase didn't change, before we would enclose the critical point. These are called phase margin and gain margin. And they're calculated at the gain crossover frequency and the phase crossover frequency, respectively.

This information can be extracted just as easily from a Bode plot. Here's an example of one. The system is stable, open loop stable, closed loop stable. The first frequency we're interested in is the gain crossover frequency, where the magnitude plot crosses below zero dB, or unity. And then we look at the phase at that frequency, and it's the difference between what phase we've got and 180 degrees. And it's that arrow there. So it's positive if we're pointing down.

And then the other frequency is the frequency at which the phase equals, in this case, minus 180 degrees. We'll project a line upwards, to the point where we cross the gain curve. Hopefully the gain is negative in decibels at that point. So that is the amount of gain, an arrow pointing up there, gain margin that we have. Positive gain margin and positive phase margin indicate stable systems.

Now sometimes you have a system which is convenient to control, but most often you don't. Most often you've got something that isn't quite what you want. So you try to improve its characteristics by modifying its frequency response. Here for example is this the closed-- the open loop polar plot, the Nyquist plot of a system which is closed loop stable, but unfortunately it doesn't have enough gain in it. You might want to put more gain in this to give us better performance at low frequencies.

And when we do that, we rotate the Nyquist curve. And unfortunately when we get the right low frequency gain, we have not got an unstable closed loop system, because the critical point is enclosed. So in this case, we would need to bend the phase curve to make sure that we get the low frequency gain we want, but we don't enclose the critical point, we don't make the system unstable. This is called phase compensation. It's the name that's given to controllers that are designed in the frequency domain to modify the phase shift of the open loop. It's also called loop shaping. When you hear phase compensation or loop shaping, they're talking about the same thing.

Now conceptually then, there are three different types of phase compensator that can be designed. By far the most common one is the phase lead compensator. Most systems have intrinsically too much phase lag. That's just the nature of the world, I guess. So we want to apply phase lead to correct for that.

Now in the simplest case, a first order case, a phase lead compensator comprises of a single zero and a single pole. And the key thing is that the zero appears at a lower frequency than the pole. The presence of a low frequency zero gives us phase lead, and then the presence of a high frequency pole gives us-- well, it contracts it to roll the phase off at high frequencies. So a phase lead compensator has a lower frequency zero than it does a pole.

Sometimes, rarely in electronics, but sometimes, we want to do the opposite. We might want to apply phase lag, perhaps to give us boost at low frequencies. And it's the same kind of arrangement, it's just that the pole appears at a lower frequency than the zero. And at other times we can get inventive by combining pole and zero combinations to apply lead in certain frequency ranges and lag in others. That's called a lag lead or lead lag compensator. It depends on the order in which you apply them.

I'm going to focus on the phase lead compensator, and we're going to do a couple of tutorials on the design of them before we break for lunch, simply because it's the most common type. Now this is the first order, phase lead compensator Bode plot. Magnitude as well as phase. And this applies to a passive phase lead compensator, one that's just simply comprised perhaps of inductors and capacitors and things like that. You see, the phase lead, which comes in from the low frequency zero, implies an attenuation at low frequencies as well. This is unavoidable with phase lead compensators of this type. There's a game change as well as a phase change.

And that's a bit unfortunate because the tuning of these things, when you design them, can't be done by purely focusing on the phase. Typically we want to, right? We know how much extra phase we want. That's the parameter called phi m, let's call it. I want that amount of phase lead, and I want it at this frequency, omega m. And what we'll do is we'll design a compensator to those parameters, and we'll find that it's wrong. We didn't get what we expected. Why not? Well, because we forgot about the gain that happens up here.

So it tends to be an iterative process. You design the compensator you think you want, and then you find that it was a mistake. So you go back and do it again, and you iterate progressively towards an optimal kind of design. I'll show you this in the tutorial very shortly.

So here's the phase plot only of the phase lead compensator. Now I'm going to show you two ways of designing them. The first way is going to be a rather manual process, which I always used to use years ago. And the second process is going to use the power of modern software to take all the effort out of it.

But the way that I used use is-- this is the form of the phase lead compensator that I want to concentrate on. There are two parameters-- see the thing is here. We know the amount of phase we want to apply, and we know the frequency that we want to apply it. Those parameters are absolutely no use when we design the compensator. We need to know the frequencies of the zero and the pole that give us those results. It's the pole and zero frequencies we're after, not these specifications. So you have to relate poles and zeroes to those two. And here's how you can do it.

By representing the phase lead compensator in this way, with two parameters I've called alpha and c, you can work out that the parameters are related by these two equations, and the logic is in the book, in the textbook. And by rearranging them, you can come up with an expression for what alpha should be in terms of theta m, the amount of phase lead you want. That defines alpha uniquely. And once you know alpha, you can get c from this equation, by just plugging in the frequency at which you want phase lead.

Now you know alpha and c, you have everything you need to construct phase lead compensator, and everything should work out. But it never does. So what I'm going to do now is I'm going to show you an example of a phase lead compensator design. This is one of the tutorials that as I mentioned, these are all on the website. You can download them and there's PDFs ad infinitum like this that you can go through.

Our transfer function has-- this is the plant that we've got. It has two poles, one at s equals minus 0.1, that's pretty close to the imaginary axis, but it's real. And one at s equals minus 1, there's no zeroes involved here. And we're aiming for a phase margin of 45 degrees, a crossover frequency of 3 radians per second. I don't know if that's feasible or not, but that's what we're aiming for. And a steady state error of 0.01.

Now because of the order in which this material has evolved, I haven't yet told you how to design for steady state error. It turns out to be a constraint on the gain in the closed loop. And the actual gain that this one turns out to be is equal to-- the steady state error is going to be equal to 1 divided by 1 plus k. And the specification is that that should be less than 1%. So the value of gain that we would want to apply to make that true would be what? k has to be 99, right? 1 divided by 99 plus 1 is 0.01. So we're going to take a value of k of 100, because it's a nice round number. And that should give us a steady state error of less than 1%.

Let's see if it does. First of all, I need a model of this plant. I use the transfer function script to do that, and its numerator and denominator. Well, the numerator was just 1, and the denominator-- well, it was 10s squared 11s plus 1, I think. That's the transfer function. So that's it, expressed in expanded form. Let's look at the tutorial again. All right, that factored out. 10s plus 1 times s plus 1. I think it's 10s squared plus 11s plus 1.

If you want to know what the transfer function looks like, in terms of poles and zeroes, you can use the function ZPK-- zero pole gain-- which will factorize it. In this case, you can see there is a pole at minus 1 at a pole at minus 0.1. So that transfer function is correct.

Now let's put a controller of 100 in here. Then that's the control that's got a gain of 100. And now what I'm going to do is, I'm going to form the closed-loop transfer function. To do that, there's a nice function called feedback, which we give-- not "foedback," but feedback-- which we give the forward and the feedback path transfer functions to. So this is the closed-loop transfer function.

And what we can do now is to evaluate the steady state response of this. Now, I could take a step response of the closed loop, and I could look at it like this. Well, it looks like it's pretty close to 1. So what I'll do is, I'll select Characteristic, Steady State. And it looks like it's pretty close to 1-- 0.99. Or what I can do is, I can evaluate the DC gain of the closed-loop transfer function. And it tells me that it's 0.9901, so we're within 1%. OK, that's great.

Now we need to know something about the phase margin, because we are tuning this compensator to achieve a phase margin of 45 degrees at 3 radians per second. That's the target specifications. And there's a nice script called Margin, and we apply this to the open loop-- the open loop-- that's what Nyquist used, when he did his mapping. So margin, f times g-- now, what happens here is it constructs a Bode plot of the open loop for us. And in addition to that, it will, very helpfully, tell us what the phase margin is. You can see it at the top of the screen here. It's 19.8 degrees at 3.08 radians per second. We're looking for 45. Not good enough. We need to do some design. OK.

Now, the first thing to do is to construct alpha and c. So alpha-- you remember what it was. It was 1 plus the sine of the phase margin-- oh, sorry-- the extra phase that we wanted, divided by 1 minus the sine of the phase that we wanted. Well, what phase shall we select? How much extra phase do we want in here?

Well, I'm going to select 30 degrees, partly because 20 plus 30 is 50, so that's giving me enough phase, and partly because I happen to know what the sine of 30 degrees actually is, so it makes the math nice and easy. Now, this is going to be equal to-- well, the sine of 30 degrees is 0.5, right? Everybody knows that. So this is 1.5 over 0.5. So obviously, alpha is going to be equal to 3. OK?

Now we need to calculate what c is. Well, what's c? Well, it's 1 over omega m times the root of alpha-- which, as I'm sure you all know, is 1 divided by 5.33. And I wouldn't like you to think that I worked that out in my head. It's just that this is the 95th seminar that I've taught, and I'm starting to remember that particular number.

Now, we can plot these straight into that formula for f of s. It's going to be 1 over alpha times 1 plus alpha times c times s over 1 plus c times s. That is the transfer function of the system that we're interested in. So let's work that out. Well, I don't need to convert that to anything special. I can keep it like that.

So f of s is going to be equal to-- well, first of all, it's got a gain of 100 in it. We can't forget that, because we need that for the steady state. It's 100 times 1 over 3-- because that's one over alpha-- times-- now, if I multiply through by c, this is going to be 3 times s plus 5.33 divided by s plus 5.33, which equals what? Well, it's 100 times-- those 3's will cancel, on the top-- we've got s plus 1.77 divided by s plus 5.33. That is the phase lead compensator I think should give me 30 degrees of phase lead at 3.08 radians per second. So let's try it.

I'm going to just clear out the screen by typing CLC, to give myself a nice workspace again. So f, now, is going to be equal to 100 times-- this transfer function is going to have 1.77 in the numerator, and the denominator is going to be equal to 1, 5.33, I think. Looks good. Now what we'll do is do margin again. So this is the margin. Let's take a look at it now. Well, we've got a nice, hefty phase margin now-- 56 degrees. Unfortunately, what we've got is the gain crossover frequency has fallen now. Why's that happened? Why do we think-- what's gone wrong here? I put the extra phase margin in. I can even see the effect of it here. See, it's gone and lifted it up. Nice phase margin, but what's gone wrong?

The amplitude change?

Yeah. We've forgotten the amplitude change. We've got a 1 over alpha in that transfer function, and it's brought the gain curve down, so it's reduced the gain crossover frequency. Even worse than that, if we look at the closed-loop transfer function-- I'll tell you what. I'll just highlight the ones I want. There's the closed-loop transfer function. And we look at its gain-- it's now 3%. So that gain has now violated the steady state error. We need to put that gain back in.

So let's do that. So here's the function we need. All I'm going to do is simply multiply the gain by 3 in here. And now what we can do is, to reconstruct the closed-loop transfer function and check the gain-- we're back up to 1%. That looks good. Now let's check the phase margin. Phase margin is now 42 degrees-- not bad, but you can see where this is going. Right? We adjust the phase. We forget the gains. We adjust the gain. We forgot the phase. And we just keep ping-ponging between these two objectives, until we, hopefully, achieve some satisfactory conclusion-- probably, 42 degrees would be acceptable. Whenever you see a full 45-degree phase margin, you know somebody just dreamt it up. So 42 is probably going to be OK. It's a nice, round number. Right? So 42 is OK.

Let's do something a little bit more complicated. Let's do a slightly more ambitious design. Now, this one is called-- this one is about a buck controller. This power supply design is called a buck, because it works like-- I'm sure you know. It works like this. There's a fixed input voltage-- I'm calling it VS-- which is switched. All right? It's chopped up by a pulse-width modulated signal through this MOSFET. So the output is a smoothed, chopped signal. It's smoothed by this inductor and capacitor network. So the output voltage is always less than the input voltage, and the two are related through the duty cycle of the PWM that's chopping up the input. Basically, that's the operation of the buck.

And there is a feedback. So the output voltage is measured. It's attenuated through this resistive divider. And then there is a compensating network here, which produces an output based on the feedback. And this thing-- this is the voltage reference coming in. So this is the controller, and that's the plant, and that's the sensor, in terms of classical canonical loop.

Now, this particular design of compensator has a name in the industry. It's called a Type 3 compensator, and it consists of an integrator and two poles and two 0's, which we place freely by selecting the passive components, in this design. And what I'm going to do is, I'm going to take an actual design of buck network, based on parameters taken from one of the TI kits that we developed. And I'm going to design a phase lead compensator to give us these characteristics down here. I'm looking for a gain margin of 10 dB, and I'm looking for a phase margin at 10 kilohertz of 45 degrees. That's another invented one-- 45 degrees at 10 kilohertz.

Now, most switching power supplies like this require zero steady-state error. And we will find later that an integrator-- the presence of an integrator-- is capable of doing that. So let me show you this design project.

Now, I've used a style of programming in-- on, no I haven't. I haven't. What I've done is, first of all, this is a script file. It's like writing a program in C. You can collect all your MATLAB statements into a single source file, and then just run through them-- execute them like you would a C file. So here is the script the captures the passive components in the buck output network-- R's and C's and L's there. And then down here, I'm combining these passive component values into the coefficients of the transfer function, and then using the TF script to build up the transfer function of the plant. This is what it happens to be. There's more description in the text.

And then at the bottom, down here, I'm using a tool called SISO tool. Now, those of you who are familiar with MATLAB for control design may have used this before. It's a nice graphical tool, which is built into the control systems toolbox in MATLAB, which allows you-- it's got some powerful features that allows you to design compensators for systems which have one input and one output. Systems which have a single input and a single output are called SISO systems-- S-I-S-O systems-- which is why it's called SISO tool.

I'm going to use the Bode response to work with. So what I'm going to do when I run this script is that MATLAB will launch SISO tool, and it'll automatically open up the Bode plot for me to work with. There is the Bode plot. We'll turn the grid on, because I like to look at the grid.

Now, this is the Bode plot, and marked on it are circles, corresponding to the zeroes of the plant, and crosses-- there are two coincident crosses here, corresponding to the complex pole pair that's in the plant. And that also gives us a resonant peak, remember, from the first section. You get a resonant peak with a very rapid change of phase for an under-damped system, with complex poles in it.

Now, I like to monitor the step response of the system as I go through this, because it just gives me an extra insight into how the loop is behaving. And to do that, I can select Analysis Plots and then select a step for the closed loop, from r to y. And there is the closed-loop step response. Obviously, that's a bit ringy, and we might want to do something about that. Whoops, where's it gone? There, OK.

Now, the compensator, remember, has an integrator, two zeroes, and two poles. Let's first of all apply the integrator. And to do that, I'm going to right-click on the Bode plot, select Add Pole Zero, and then select Integrate. And as I do this, the presence of an integrator-- remember, a pole at 0 Hertz is going to induce a low-frequency roll-off minus 20 dB per decade. So this curve here, which is now currently flat-- this is the open loop, at the moment-- this is going to acquire a slope.

And associated with that slope is going to be a phase lag of minus 90 degrees, because that's what integrators do. So we'll select integrate. But what it'll do for us is, it'll remove the steady-state error. At the moment, steady-state error is about 0.18 or something. And integrator should get rid of that. So let's do that. There we go.

So the steady-state error is gone. Right? Here's the slope, and there's the phase, minus 90 degrees. Now, the reason that it says unit step input and the steady-state error is 0, but it's actually outputting too, is because of the feedback in network. We've got an attenuation of a half in the feedback network, and that gives you an output of 2 in steady state, when there's no error.

OK, now we want to work towards those characteristics of 45 degrees at 10 kilohertz and 10 dBs. Well, at the moment the gain margin's nice and healthy. There's the gain margin, at the phase crossover frequency, which is 4.86 times 10 to the fourth. That's not high enough. All right? That needs to be up a little bit higher. So what I'm going to do is, I'm going to add gain to the compensator. All I'm going to do is drag this up. I'm dragging the magnitude plot of the open loop, and therefore the compensator, along with it-- the rise time of the step response getting shorter.

And unfortunately, what's going to happen here is that-- let me just stop there for a second. This is the gain crossover frequency-- the frequency at which phase margin is measured. And you see, it's very big. We're aiming for 45 degrees. And we're aiming, down here, for 6.28 times 10 to the 4 radians per second. That's 10 kilohertz. I want to drag this up to get that high enough. That's the gain crossover frequency. And this has to stay above 10 dB, as well.

Unfortunately, what's going to happen is-- see that peak in the magnitude curve? That's going to break through the 0 db line and the thing's going to become unstable, because that's peaking at the point where we've got 180 degrees of phase shift. So just watch what happens as we get close to the 0 db line. Here we go. See, we've got that far. Now, see the oscillation that's just peeking through here? And then that's going to become unstable, and the gain crossover frequency is going to jump in a second, to-- there, see? It's gone unstable at that point. But I can't quite get this frequency high enough. We need to apply a phase lead compensator.

Now, there are various papers written on this type of compensator, but it's generally reckoned that the best way to design them is to place a pair of complex 0's right on top of this complex pole pair that defines this peak, and then to place the other poles that you don't need at higher frequencies. They don't actually help much, because they induce phase lag, and we've got plenty of phase lag to go around.

So I'm going to place a pair of complex 0's like this. I'm going to drag a pair of complex 0's there, and just drop it straight on top of that peak there. And what it's done is, it's made the peak much sharper. Well, don't worry about that too much. Look what it's done for the phase. Those two 0's have lifted the phase curve up. So we've now gone well away from 180 degrees. This thing isn't unstable. Can put whatever gain I like in. It's not unstable.

I now need two poles. We'll select real poles, and we'll put them at high frequencies, right out here somewhere-- well beyond 10 kilohertz, where they're not hurting us. And by the way, if you change your mind, you can just drag them around like that.

So now we can increase the gain, pretty much with impunity. There's the-- in the bottom curve is the gain crossover frequency and the phase margin. Let's put it here. So if I drag it up-- so this line is now right in this bulge-- this bulge is the effect of the phase lead compensator coming in. I can put the phase nicely-- the gain crossover frequency right in the middle of that, somewhere like that. Look at the step response now, bearing in mind these are tens of microseconds. That's rather nice. My phase margin is 72 degrees, and the frequency-- well, it's an order of magnitude higher than I require it to be. Gain margin is infinite, because we never cross over 180 degrees. There's no phase crossover frequency now.

So that, on the face of it, is a good design. Let's take a look at it. Here's the compensator. It consists of an integrator, a complex zero pair, and then two real poles. We can export this back into the workspace now and manipulate it. We'll export the compensator like this. So now, when I'm back in the workspace, the variable c corresponds to the compensator that I've just designed. OK? It looks big numbers in there, but that's what it is.

Now, we can play around with these a little bit more by taking that transfer function. And what I've done in this script is, I've tried to extract reasonable passive values from that design, so I can relate it to things like resistors and capacitors. Now, I've used a technique called cell programming in MATLAB. You see, in MATLAB, where you put a percent symbol in, like that, it acts a little bit like two forward slashes in C. It just comments out the rest of the line. But where you put two percent symbols next to one another, it separates the program into what's called cells. So that's one cell, between a double percent here and a double percent here, and likewise, further down.

And those are nice, because you can execute one and then stop. They're a bit like breakpoints in your program. So I can execute this first cell up here, which is going to extract the frequencies of the poles and zeroes. And I do it by just clicking on Run and Advance. So there are the frequencies of the poles and zeroes. From them, we'll try and fit passive values. We have to make a couple of choices. I've chosen r3 and c2. And it'll calculate the remaining ones for me.

And then we'll draw a Bode plot. This is the Bode plot of the phase lead compensator that we've just designed. You can see it is a phase lead compensator. It gives us a nice phase lead over a range of frequencies. It's also an integrator. The minus 90 degrees and the low-frequency minus 1 slope tell us there's an integrator involved, and we know that this is going to meet our requirements.

So my intention here is just to show you the two different ways of designing a phase lead compensator. There's the good old way, with a paper and pencil or a whiteboard and a marker, where you go through the old iterative approach. Or you can take the hard work out of iteration and use something like a SISO tool, because the hard work is just extracted from the process by taking advantage of the tools.

